{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd2ca41-dd12-41fb-9216-3aca34ba9b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scaler import StandardScaler\n",
    "from  sample_data_logistic_reg import load_sample_data\n",
    "from logistic_regression import LogisticRegressionScratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b3cba-e1c0-402e-932f-a6e13ef1e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data \n",
    "import pandas as pd\n",
    "\n",
    "X, y = load_sample_data()\n",
    "df = pd.DataFrame(\n",
    "    X,\n",
    "    columns=[\"Feature_1\", \"Feature_2\"]\n",
    ")\n",
    "\n",
    "df[\"Target\"] = y\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf20da-d389-4c9a-8153-b603c49d955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Implementation\n",
    "\n",
    "# Load data\n",
    "X, y = load_sample_data()\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegressionScratch(\n",
    "    learning_rate=0.1,\n",
    "    n_iter=1000,\n",
    "    verbose=True\n",
    ")\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "# Predictions (class labels)\n",
    "y_pred = model.predict(X_scaled)\n",
    "misclassified = y_pred != y\n",
    "\n",
    "# Probabilities\n",
    "y_prob = model.get_probabilities(X_scaled)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = np.mean(y_pred == y)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Predictions:\", y_pred)\n",
    "print(\"Probabilities:\", np.round(y_prob, 3))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=y, cmap=\"bwr\", edgecolor=\"k\")\n",
    "\n",
    "# Decision boundary: w1*x1 + w2*x2 + b = 0\n",
    "x1_vals = np.linspace(\n",
    "    X_scaled[:, 0].min() - 1,\n",
    "    X_scaled[:, 0].max() + 1,\n",
    "    100\n",
    ")\n",
    "\n",
    "x2_vals = -(model.weights[0] * x1_vals + model.bias) / model.weights[1]\n",
    "\n",
    "plt.plot(x1_vals, x2_vals, color=\"black\", label=\"Decision Boundary\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.title(\"Logistic Regression from Scratch\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Loss Curve\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(model.losses, linewidth=2)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.title(\"Training Loss Convergence\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56057ff8-84bc-4a33-8caa-b7f8b2ad9210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
